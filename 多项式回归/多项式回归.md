[toc]

# 多项式回归

对于非线性的数据，我们用线性回归的效果是不理想的，所以我们要考虑用多项式回归。对于$y=ax^2+bx+c$，这本身是一个线性回归的例子，从x的角度看，是一个非线性的方程。这就是**多项式回归**

## 算法实现

```python
import numpy as np
# 构造数据集
X = np.random.uniform(-3,3,size=100)
X=X.reshape(-1,1)

y=0.5*X**2+ X + 2
# 添加噪音
ran = np.random.normal(0,1,size=100).reshape(-1,1)
y = y + ran

# 使用线性回归来拟合数据集
from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X,y)

# 但是，经过绘制直线发现拟合效果并不好

# 解决方法，添加一个特征
X2 = np.hstack([X,X**2])

# 建模
lin_reg2 = LinearRegression()
lin_reg2.fit(x2,y)
y_predict = lin_reg2.fit(X2,y)

plt.scatter(x,y)
plt.plot(np.sort(x[:,0]),y_predict[np.argsort(x[:,0])],'r')
plt.show()
```

这实际是一种对数据集升维的过程

## scikit-learn中的 PolyNomialFeatures

在多项式回归中，我们也需要做数据预处理，我们常用的是scikit-learn 中的PolynomiaFeatures

```python
from sklearn.preprocessing import PolynomiaFeatures
poly = PolynomiaFeatures(degree)# degree为几次幂
X2 = poly.transform(X)
```

实际上是这样的

```python
# 原始的数据[x1,x2]
# 当degree=2时，transform后的数据为[1,x1,x2,x1**2,x2**2,x1*x2]
```

$$
同理，degree=3
\\1,x_1,x_2
\\x_1^2,x_2^2,x_1x_2
\\x_1^3,x_2^3,x_1^2x_2,x_1x_2^2
$$

## 使用Pipeline

什么时pipline?

**Pipeline**可以将许多算法模型串联起来，比如将特征提取、归一化、分类组织在一起形成一个典型的机器学习问题工作流。主要带来两点好处：

1. 直接调用fit和predict方法来对pipeline中的所有算法模型进行训练和预测。
2. 可以结合grid search对参数进行选择。

总而言之，就是可以将几个数据预处理的步骤合并到一起，然后可以减少我们的工作。

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandarScaler
# 传入每一个步骤所对应的类
poly_rag = Pipeline([
    ("poly",PolynomialFeatures(degree=2)),
    ("std_scaler",StandarScaler()),
    ("lin_reg",LinearRegression())
])
# 相当于我们创建了一个适合多项式回归的一个类
poly_reg.fit(X,y)
y_predict = reg_reg.predict(X)
```

## 过拟合与欠拟合

多项式回归是我们解决非线性问题的一个很好的，但是过度使用，会造成过拟合的问题。多项式回归与线性回归一样，能够用均方误差或者R方来衡量准确率。

```python
from sklearn.metrics import mean_squared_error
y_predict = lin_reg.predict()
```

```python
def PolynomialRegreession(degree):
    return Pipeline([
        ("poly",PolynomialFeatures(degree=2)),
        ("std_scaler",StandarScaler()),
        ("lin_reg",LinearRegression())
	])
```

degree越大，对于训练集来说，score越高，但是，实际上，已经过拟合了(Overfitting)。如果过拟合，泛化能力会下降。

## 过拟合的解决

### 划分训练集和测试集

 在测试集上建立模型，在测试集上测试。训练集的准确率一般比测试集高。随着模型复杂度增加，训练集的准确率呈增大的趋势，测试集的准确率呈先增大后减小的趋势。

- 欠拟合 underfitting ：算法所训练的模型不能完整表述数据关系
- 过拟合 overfitting ：算法所训练的模型过多地表达了数据集间地噪音关系。

## 学习曲线

学习曲线指的是：随着训练样本地逐渐增多，算法训练出地模型的表现能力。

下面是学习曲线的绘制：

```python
import numpy as np
import matplotlib.pyplot as plt
np.random.seed(666)
# 构造数据集
X = np.random.uniform(-3,3,size=100)
X=X.reshape(-1,1)
y=0.5*X**2+ X + 2
# 添加噪音
ran = np.random.normal(0,1,size=100).reshape(-1,1)
y = y + ran

# 学习曲线
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)
from 

from sklearn.linear_model import LinearRegression
train_score=[]
test_score=[]
for i in range(1,76):
    lin_reg = LinearRegression()
    lin_reg.fit(X_train[:i],y_train[:i])
    
    y_train_predict = lin_reg.predict(X_train[:i])
    train_score.append(mean_squared_error(y_train[:i],y_train_predict))
    y_test_predict = lin_reg.predict(X_test)
    test_score.append(mean_squared_error(y_test,y_test_predict))
    
    
# 绘制曲线
plt.plot([i for i in range(1,76)], np.sqrt(train_score), label="train")
plt.plot([i for i in range(1,76)], np.sqrt(test_score), label="test")
plt.legend()
plt.show()
```

![image-20210531000818475](image-20210531000818475.png)

```python
def plot_learning_curve(algo, X_train, X_test, y_train, y_test):
    train_score=[]
    test_score=[]
    for i in range(1,len(X_train)+1):
        algo.fit(X_train[:i], y_train[:i])
        y_train_predict = algo.predict(X_train[:i])
        train_score.append(mean_squared_error(y_train[:i],y_train_predict))
        y_test_predict = algo.predict(X_test)
        test_score.append(mean_squared_error(y_test,y_test_predict))
    
    # 绘制曲线
    plt.plot([i for i in range(1,len(X_train)+1)], np.sqrt(train_score), label="train")
    plt.plot([i for i in range(1,len(X_train)+1)], np.sqrt(test_score), label="test")
    plt.legend()
    plt.axis([0,len(X_train)+1,0, 4])
    plt.show()
```

![image-20210531001932792](image-20210531001932792.png)

