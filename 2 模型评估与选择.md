[toc]

# 第二章 模型评估与选择

通常把分类错误的样本数占样本总数的比例称为“错误率”，即如果在m个样本中有a个样本分类错误，则错误率为$E=\frac{a}{m}$;相应地，我们将$1-\frac{a}{m}$称为“精度”。即“精度”=1-错误率

如果学习器把样本数据训练得太好了，那么很可能已经把训练样本自身的一些特点当作了所有潜在样本都具有的一般性质，这样就会导致泛化性能下降。这种现象成为过拟合，与”过拟合”相对的就是“欠拟合”。

欠拟合比较容易克服，比如在决策树学习中扩展分支，在神经网络学习中增加训练轮数。

过拟合是无法避免的，那么选择哪一种学习算法，就是机器学习中“模型选择”问题。

### 评估方法

1、留出法 ： 直接将数据集D划分层两个互斥的集合，其中一个集合作为训练集S，另一个集合作为测试集T。即$$D=S\cup T,S\cap T=\varnothing$$ 一个作为训练集，一个作为测试集

2、交叉验证法 K折交叉验证 留一法 sklearn可以实现

3、自助法 适用于数据集较小，难以有效划分数据、测试集时很有用。此外，自助法能初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。

**自助法**：每次随机从D中挑选一个样本，将其拷贝放入D'，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍可能被采集到，这个过程重复了m次后，我们得到了包含m个样本的数据集D'，这就是自主采样的结果。其中有一部分会在D'中出现多次，有些不出现。样本在m次采样中始终不被采到的概率是$(1-\frac{1}{m})^{m}$ 。取极限可得概率。
$$
\lim_{m\rightarrow \infin}(1-\frac{1}{m})^{m}=\frac{1}{e}\approx 0.368
$$

使用这样的数据的测试结果，我们称之为“保外估计”。**适用于数据集较小，难以有效划分数据、测试集时很有用。**

### 调参与最终模型

参数配置不同。学习的模型的性能往往会有显著差异。因此，在进行模型评估与选择时，除了要对适用许欸算法进行选择，还需要对算法参数进行设定。

现实中，学习算法的调参方法是在实数范围内取直，我们常选定一个范围和变化步长。例如在$[0,0.2]$范围内，以0.05为步长，那么评估的数有5个。注意，要在计算开销和性能估计之间进行折中。**参数调的好不好，是最终模型性能好坏的关键**

### 性能度量

回归任务最常用的性能度量是**“均方误差”(mean squared error)** f 为学习器，D=$\left\{(x_1,y_1),(x_2,y_2),\dots , (x_m,y_m)\right\}$
$$
E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(x_i)-y_i)^2
$$
更一般的，对于数据分布$D$的概率和密度函数$p()$，均方误差可描述为
$$
E(f;D)=\int_{x\sim D}(f(x)-y)^2p(x)dx
$$

### 错误率与精度

错误率与精度，是分类任务中最常用的两种性能度量，既适用于二分类任务，也适用于多分类任务

分类错误率定义为：
$$
E(f;D)=\frac{1}{m}\sum_{i=1}{m}I(f(x_i)\neq y_i)
$$


则，精度的定义为
$$
\begin{align}
acc(f;D)&=\frac{1}{m}\sum_{i=1}^{m}I(f(x_i)=y_i)\\
     &= 1-E(f;D)
\end{align}
$$


查准率、查全率和F1

